FRENCH:

# This deletes the last line of each file ($ is last line, d is delete)
for l in en fr; do for f in /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/*.$l; do if [[ "$f" != *"test"* ]]; then sed -i "$ d" $f; fi;  done; done
for l in en fr; do for f in /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done
python preprocess.py -train_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.en.atok -train_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.fr.atok -valid_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.en.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.fr.atok -save_data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr.atok
python preprocess.py -train_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.en.atok -train_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_train.fr.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.en.atok -valid_src /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr/baseline-1M_valid.fr.atok -save_data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-fren.atok

python train.py -data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-enfr.atok -save_model trained_models/english_french_model -gpuid 0
python train.py -data /home/marcotcr/phd/OpenNMT-py/Recipes/baseline-1M-enfr/data/baseline-1M-fren.atok -save_model trained_models/french_english_model -gpuid 1

German:

for l in en de; do for f in /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done
# concat stuff
for l in en de ; do cat /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/commoncrawl.de-en.$l.atok /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/europarl-v7.de-en.$l.atok /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/news-commentary-v10.de-en.$l.atok > /home/marcotcr/phd/OpenNMT-py/phd/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.$l.atok ; done
dd if=/dev/urandom of=/tmp/myrand count=100024
shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.en.atok > /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok
shuf -n 2500000 --random-source /tmp/myrand /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en-big.de.atok > /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok

python preprocess.py -train_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok -train_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok -valid_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.en.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.de.atok -save_data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-ende.atok
python preprocess.py -train_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.en.atok -train_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/wmt15-all-de-en.de.atok -valid_tgt /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.en.atok -valid_src /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-de-en/newstest2013.de.atok -save_data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-deen.atok

python train.py -data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-ende.atok -save_model trained_models/english_german_model -gpuid 0
python train.py -data /home/marcotcr/phd/OpenNMT-py/wmt15-ende/wmt15-deen.atok -save_model trained_models/german_english_model -gpuid 1

Portuguese:
for l in en pt; do for f in /home/marcotcr/phd/datasets/translation/data_for_onmt/*.$l; do perl tokenizer.perl -a -no-escape -l $l -q  < $f > $f.atok; done; done

python preprocess.py -train_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.en.atok -train_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.pt.atok -valid_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.en.atok -valid_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.pt.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_enpt.atok
python preprocess.py -train_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.en.atok -train_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_train.pt.atok -valid_tgt /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.en.atok -valid_src /home/marcotcr/phd/datasets/translation/data_for_onmt/all_val.pt.atok -save_data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_pten.atok

python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_enpt.atok -save_model trained_models/english_portuguese_model -gpuid 0
python train.py -data /home/marcotcr/phd/datasets/translation/data_for_onmt/data_pten.atok -save_model trained_models/portuguese_english_model -gpuid 1
